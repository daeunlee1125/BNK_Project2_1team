import 'package:flutter/material.dart';

import '../core/voice_intent.dart';
import '../core/voice_state.dart';
import '../core/voice_state_machine.dart';
import '../intent/voice_intent_classifier.dart';
import '../script/voice_script_resolver.dart';
import '../service/voice_stt_service.dart';
import '../service/voice_tts_service.dart';
import '../ui/voice_ui_state.dart';

class VoiceSessionController {
  final VoiceSttService stt;
  final VoiceTtsService tts;
  VoiceStateMachine fsm;

  final ValueNotifier<VoiceUiState> uiState =
  ValueNotifier(VoiceUiState.idle);
  final ValueNotifier<double> volume =
  ValueNotifier(0.0);

  final bool autoListenAfterTts = true;
  VoiceState _currentState = VoiceState.idle;

  VoiceSessionController({
    required this.stt,
    required this.tts,
    required this.fsm,
  }) {
    tts.onComplete(() async {
      uiState.value = VoiceUiState.idle;
      await Future.delayed(const Duration(milliseconds: 250));
      if (autoListenAfterTts && _shouldAutoListen(_currentState)) {
        startListening(fromAuto: true);
      }
    });

    final originalFsm = fsm;

    fsm = VoiceStateMachine(
      initialState: originalFsm.state,
      productCode: originalFsm.productCode,
      onStateChanged: _onStateChanged,
    );
  }

  void startSession() {
    // ì„¸ì…˜ ì‹œì‘ ì‹œ FSMì„ idleë¡œ "ì˜ë„ì ìœ¼ë¡œ" ì§„ì…ì‹œí‚´
    fsm.enterInitial();
  }

  Future<void> _onStateChanged(VoiceState state) async {
    _currentState = state;
    final script = VoiceScriptResolver.resolve(state);
    if (script.isNotEmpty) {
      uiState.value = VoiceUiState.speaking; // âœ… ì•ˆë‚´ ì¤‘
      await tts.speak(script);
    }
  }




  void startListening({bool fromAuto = false}) {
    if (!fromAuto) tts.stop();

    stt.startListening(
      onResult: _onSpeechResult,
      onSoundLevel: (rms) {
        volume.value = rms; // âœ… íŒŒí˜•
      },
      onStatus: (s) {
        if (s == 'listening') {
          uiState.value = VoiceUiState.listening; // âœ… ë“£ê³  ìˆì–´ìš”
        } else if (s == 'done' || s == 'notListening') {
          uiState.value = VoiceUiState.thinking;
        }
      },
      onError: (_) {
        uiState.value = VoiceUiState.idle;
      },
    );
  }

  void stopListening() {
    stt.stop();
    uiState.value = VoiceUiState.thinking;
  }

  void _onSpeechResult(String text) async {

    debugPrint('ğŸ¤ [STT RESULT] "$text"');

    // ë„¤íŠ¸ì›Œí¬ / ì„œë²„ëŠ” ë°˜ë“œì‹œ try-catch
    try {
      final result = await VoiceIntentClassifier.classify(text);

      debugPrint(
        '[INTENT RESULT] intent=${result.intent}, product=${result.productCode}',
      );

      if (result.productCode != null) {
        fsm = fsm.withProduct(result.productCode!);
      }

      fsm.onIntent(result.intent);

    } catch (e, s) {
      // ì—¬ê¸°ë¡œ ì˜¤ë©´ ë„¤íŠ¸ì›Œí¬/DNS ì‹¤íŒ¨
      debugPrint('âŒ [INTENT ERROR] $e');
      debugPrint('$s');

      // UI ë³µêµ¬
      uiState.value = VoiceUiState.idle;

      // ì‚¬ìš©ìì—ê²Œ ìŒì„±ìœ¼ë¡œ ì•Œë ¤ì£¼ê¸°
      tts.speak('ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
    }
  }


  bool _shouldAutoListen(VoiceState state) {
    return state == VoiceState.idle ||
        state == VoiceState.joinConfirm ||
        state == VoiceState.s4Input;
  }

  void _onVolume(double rms) {
    // overlay waveform ì—…ë°ì´íŠ¸
  }
}
